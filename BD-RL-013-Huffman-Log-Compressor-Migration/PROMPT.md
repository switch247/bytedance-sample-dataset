<!-- this file is here because this is a sample don't add this to your project -->
# Huffman-Log-Compressor-Migration

**Category:** Code Migration  
**Difficulty:** Easy-Medium

## Problem Statement
The objective is to port a Huffman coding compression utility from a high-level Python implementation to a performance-oriented Go service. The current Python version is unsuitable for processing multi-gigabyte log files because its approach to bit-manipulation is inefficient and consumes excessive memory during tree construction. The Go implementation must prioritize bitwise operations and streaming I/O to achieve production-grade throughput while maintaining a minimal, predictable memory footprint.

## Engineering Assignment
You are a Senior Platform Engineer at LogScale, a company that processes and archives massive volumes of server logs. Our internal compression utility, currently written in Python, has become a significant bottleneck. While functionally correct, the Python implementation relies on string-based bit representations and lacks the performance required to handle the multi-gigabyte files generated by our edge nodes. We need to migrate this core logic to Go to take advantage of its low-level bit manipulation capabilities and its ability to handle large-scale streaming data with minimal overhead.

### Assignment Scope
You are required to port the logic from the provided Python source code into two separate Go files. 
1. The first file should contain the internal data structures, frequency analysis logic, and the Huffman tree construction algorithm. 
2. The second file should contain the public API for encoding and decoding, as well as the bit-packing logic. 

Your Go implementation must be compatible with the serialization format of the Python version, allowing data compressed in Python to be decompressed in Go and vice versa.

### Technical Constraints and Boundary Conditions
1. **Bitwise Performance:** You must implement manual bit-packing using native bitwise operators like shifts and masks. Under no circumstances should you use string-based binary representations (such as '0101') for the compressed output, as this defeats the performance goals of the migration.
2. **Streaming Requirements:** The implementation must support streaming via `io.Reader` and `io.Writer` interfaces. This ensures the system can process files significantly larger than the available physical RAM without triggering system-wide memory exhaustion.
3. **Serialization Parity:** To ensure compatibility, the Huffman tree structure must be serialized and included as a header in the compressed output. The decoder must be able to reconstruct the tree from this header before decompressing the remaining payload.
4. **Byte Alignment:** The encoder must handle byte-alignment by applying necessary padding to the final byte of the bitstream. The decoder must be able to identify and ignore this padding based on metadata in the header.
5. **Error Handling:** The engine must provide robust error reporting for corrupted headers, invalid bitstreams, or empty input streams.

### Definition of Done
1. The Go package is successfully implemented and split across the requested two files.
2. The code utilizes native bitwise operations for all compression and decompression logic.
3. The Go implementation can successfully decompress files generated by the legacy Python script.
4. The system demonstrates a significant reduction in processing time compared to the Python baseline when handling large datasets.
5. The implementation passes all integrity tests and correctly handles various edge cases including single-character inputs and empty files.

## Legacy Code Implementation

### huffman_core.py
```python
import heapq
from collections import Counter

class HuffmanNode:
    def __init__(self, char, freq):
        self.char = char
        self.freq = freq
        self.left = None
        self.right = None

    def __lt__(self, other):
        return self.freq < other.freq

class HuffmanLogic:
    def build_tree(self, data):
        # Frequency analysis of the input byte data
        freqs = Counter(data)
        # Build a priority queue for leaf nodes
        priority_queue = [HuffmanNode(char, freq) for char, freq in freqs.items()]
        heapq.heapify(priority_queue)

        # Iteratively merge nodes to form the binary tree
        while len(priority_queue) > 1:
            left = heapq.heappop(priority_queue)
            right = heapq.heappop(priority_queue)
            merged = HuffmanNode(None, left.freq + right.freq)
            merged.left = left
            merged.right = right
            heapq.heappush(priority_queue, merged)

        return priority_queue[0] if priority_queue else None

    def generate_codes(self, node, current_code="", codes={}):
        if node is None:
            return
        if node.char is not None:
            codes[node.char] = current_code
            self.generate_codes(node.left, current_code + "0", codes)
            self.generate_codes(node.right, current_code + "1", codes)
            return codes
```

### huffman_service.py
```python
from huffman_core import HuffmanLogic

class HuffmanService:
    def __init__(self):
        self.logic = HuffmanLogic()

    def compress(self, data):
        if not data:
            return b""
        tree = self.logic.build_tree(data)
        codes = self.logic.generate_codes(tree)
        
        # Python string concatenation approach is the primary performance bottleneck
        encoded_str = "".join([codes[char] for char in data])
        
        # Calculate padding needed for byte alignment
        padding = 8 - (len(encoded_str) % 8)
        encoded_str += "0" * padding
        
        # Manual conversion of bit-string to bytearray
        b = bytearray()
        for i in range(0, len(encoded_str), 8):
            byte = encoded_str[i:i+8]
            b.append(int(byte, 2))
        return bytes(b)
```

## Data Shapes
*   **Input:** Raw byte slice or stream.
*   **Frequency Table:** Mapping of 8-bit integers to their respective occurrence counts.
*   **Tree Header:** Serialized representation of the Huffman tree required for reconstruction.
*   **Encoded Payload:** Packed bitstream consisting of variable-length codes.

## Requirements
*   The Go implementation must utilize a priority queue using the `container/heap` package to construct the Huffman tree based on the provided character frequencies.
*   The codebase must be organized into exactly two files: one for internal logic and structures, and one for the public API and bit-packing operations.
*   The system must use bitwise operators (shifts, ORs, ANDs) to perform bit-packing into byte buffers, strictly avoiding string-based binary manipulation.
*   A serialized header containing the Huffman tree structure must be included in the output to allow the decoder to reconstruct the tree without the original data.
*   The encoder must handle padding for the final byte and store the padding count or relevant metadata in the header to ensure lossless decompression.
*   The public API must provide functions that accept `io.Reader` and `io.Writer` to support processing of files that exceed available system memory.
*   The implementation must ensure that the memory consumed by the frequency analysis and tree building phases does not grow linearly with the input file size.
*   The decoder must successfully reconstruct the original byte data from any bitstream generated by the provided Python service.
*   The service must handle input data containing the full range of 256 possible byte values and maintain integrity for files with only one unique character.
*   **Testing:** You must provide a unit test that compresses a random 10KB string and asserts that the Go decoder perfectly restores the original data.
*   **Testing:** A validation test must confirm that for a 50MB log sample, the Go implementation completes the task significantly faster than the Python baseline.
*   **Testing:** An adversarial test must verify that the system returns a specific error if the input stream is truncated or the header is corrupted.

## Metadata

### Programming Languages
*   Python
*   Go

### Libraries & Tools
*   `container/heap`
*   `io`
*   `bufio`
*   `encoding/binary`
*   `go test`
*   `go build`

### Key Concepts
*   Huffman Coding
*   Bitwise Manipulation
*   Tree Traversal
*   Priority Queues
*   Streaming I/O
*   Serialization

### Best Practices
*   Buffer Reuse
*   Resource Management
*   Interface Segregation
*   Memory Safety

### Performance Metrics
*   **Throughput:** >50MB/s
*   **Memory Efficiency:** O(1) space relative to file size
*   **Latency:** Sub-second for standard log files

### Security Standards
*   Boundary Validation
*   Input Sanitization
*   Error Shielding